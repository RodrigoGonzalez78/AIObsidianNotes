### 1. Introducción y Fundamentos

Los **Sistemas Expertos Probabilísticos** surgen para manejar la incertidumbre, común en la mayoría de las aplicaciones del mundo real.

- **Relación con sistemas deterministas:** Un SE determinista es un caso particular de uno probabilístico. Los sistemas deterministas suelen degradarse cuando el problema sale de su área de especialización.
- **Aplicación:** Son útiles en problemas con aleatoriedad (juegos de azar) o donde se carece de una descripción determinista completa (muchas excepciones).
- **Ejemplos Históricos:**
    - **MYCIN:** Recomendador de terapia para infecciones bacterianas.
    - **CASNET:** Sistema de diagnóstico médico.
    
---

### 2. Componentes de un SE Probabilístico

La arquitectura incluye sensores, interfaz de usuario, base de datos, memoria de trabajo y subsistemas de aprendizaje y explicación.

#### A. Base de Conocimiento (BC)

- Se forma por un conjunto de variables ($X_1...X_n$) y un **modelo probabilístico** representado por una **función de probabilidad conjunta** $p(x_1...x_n)$ 
- Esta función describe las relaciones entre las variables y su correcta definición es crítica para el funcionamiento del sistema.
- Es necesario actualizar periódicamente las probabilidades para asegurar la consistencia y evitar conclusiones absurdas.

#### B. Motor de Inferencias

- Es el mecanismo que extrae conclusiones usando la memoria de trabajo y la BC.
- La calidad de los resultados depende directamente de la precisión con la que se haya definido la función de probabilidad conjunta.
- Si la estructura de dependencia se desconoce, debe inferirse de datos previos.

#### C. Subsistema de Aprendizaje

Otorga flexibilidad para adaptar el modelo. Existen dos tipos:
1. **Aprendizaje Paramétrico:** Facilita la modificación del espacio de probabilidades y valores de las variables.
2. **Aprendizaje Estructural:** Define la estructura de dependencia, seleccionando las variables más relevantes y eliminando las que aportan poca información para optimizar el procesamiento.

---

### 3. Teorema de Bayes y Probabilidad

El marco teórico se basa en la **teoría estadística Bayesiana**, cuyo concepto fundamental es la probabilidad condicional $P(Ho|E)$ (Probabilidad de la Hipótesis dada la Evidencia).

- **Variables:** Se distinguen variables objetivo (categorías/hipótesis) y variables aleatorias (evidencias). Sus valores asumen el rango $[0, 1]$.
- **Probabilidad a posteriori:** Se obtiene a partir de la probabilidad _a priori_ y la verosimilitud usando el Teorema de Bayes.
- Fórmula:
    $$P(H|E)=\frac{P(E|H)P(H)}{P(E)}$$
    Esto permite calcular la probabilidad de una causa (Hipótesis $H$) dado un efecto (Evidencia $E$).

**Limitaciones del Teorema de Bayes puro:**

- Al incluir múltiples evidencias ($E_1, E_2...$), el número de probabilidades conjuntas a estimar crece exponencialmente.
- Requiere métodos de propagación de evidencia más eficientes si el número de variables es alto.
---

### 4. Modelos de Propagación de Evidencias

Para manejar la complejidad, se utilizan diferentes modelos que varían según cómo tratan la independencia de las variables. Estos modelos actualizan el valor de la variable objetivo cuando aparecen nuevas evidencias.

#### A. Modelo de Evidencias Dependientes (MSD)

- Requiere almacenar probabilidades marginales y condicionales para _todos_ los posibles valores de la variable objetivo y sus evidencias .
- También almacena probabilidades para variables irrelevantes ($p_j$).

#### B. Modelo de Evidencias Independientes (MSI)

- Es una simplificación del MSD.
- Asume que las variables evidenciales son **independientes** dada la variable de diagnóstico.
- Fórmula simplificada:
    $$p(g|v_{1},...,v_{n})=\frac{p(g)\prod_{j=1}^{n}p(v_{j}|g)}{p(v_{1},...,v_{n})}$$
    Esto reduce considerablemente el número de parámetros necesarios
#### C. Modelo de Evidencias Relevantes Independientes (MSRI)
- El diagnóstico se basa en la probabilidad condicional dada solo las variables relevantes.
- Asume independencia, por lo que la probabilidad tras conocer nuevas evidencias es proporcional a $p(v_j|g_i)$.

#### D. Modelo de Evidencias Relevantes Dependientes (MSRD)
- Funciona como un compromiso entre el MSD y el MSRI.
- **Supuesto:** Considera que los síntomas **irrelevantes son independientes**, pero asume que los síntomas **relevantes pueden ser dependientes** entre sí (ya que suelen producirse en grupos).