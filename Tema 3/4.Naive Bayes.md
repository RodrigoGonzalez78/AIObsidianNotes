
### 1. Introducción a los Sistemas Expertos (SE) Probabilísticos

Estos sistemas surgieron como respuesta para mitigar los defectos de los SE determinísticos.
- **Conceptos Clave:**
    - **Variable objetivo:** También llamada hipótesis o categoría (lo que se quiere descubrir).
    - **Variable evidencial:** También llamada característica (los datos o síntomas observados).
- **Críticas principales:**
    - Requieren conocer todas las evidencias para definir la función de probabilidad conjunta.
    - Asumen la **independencia entre variables**, una situación que a menudo es poco realista en el mundo real.

---

### 2. Aspectos de Construcción y Validación

Para desarrollar un SE probabilístico robusto, se deben considerar cuatro pilares:

1. **Calidad de los datos:** La precisión de la información proporcionada depende directamente de la calidad y cantidad de los datos usados para el aprendizaje.
2. **Complejidad del modelo:** Se debe decidir entre simplicidad y complejidad basándose en el número de variables, disponibilidad de datos y eficiencia computacional.
3. **Validación:** Es necesario utilizar datos externos (distintos a los de entrenamiento) para medir el rendimiento y precisión.
4. **Ética y Responsabilidad:** Se debe involucrar a expertos del dominio en el diseño y recordar que el sistema es una herramienta de apoyo a la toma de decisiones.

---

### 3. Modelos Naive Bayes (NB)

Naive Bayes es una familia de clasificadores probabilísticos basados en el Teorema de Bayes.
- **La suposición "Ingenua" (Naive):** Asume que las variables explicativas (características) son **independientes entre sí** dado el valor de la clase. Es decir, el efecto de una variable no depende de las otras.
- **Características:**
    - Es fácil de interpretar, entrenar y ajustar parámetros.
    - Funciona bien en _datasets_ con numerosas variables y problemas multiclase.
    - Como clasificador tiene un comportamiento aceptable, aunque existen mejores métodos para la estimación pura.

#### Tipos de Distribución

La implementación varía según los datos:
- **Gaussiana:** Se asume distribución normal para variables continuas.
- **Multinomial:** Se usa para variables discretas (generalización de la binomial).

---

### 4. Fundamento Matemático

El objetivo es calcular la probabilidad de que una instancia pertenezca a una categoría $C_j$ dadas las características $X_1...X_p$:
$$P(y=C_j|X_1...X_p)$$

Al aplicar el Teorema de Bayes y la suposición de independencia, el cálculo se simplifica:
1. La probabilidad condicional se convierte en el producto de las probabilidades individuales de cada característica:
    $$\prod_{j=1}^{p}P(x_{j}|y=C_{j})$$

2. Regla de Decisión: Para clasificar, se busca la categoría que maximice el producto de la probabilidad a priori de la clase y la probabilidad condicional de las características (el denominador se ignora porque es constante para todas las clases).
    $$C_{j}=argmax_{C_{j}}P(y=C_{j})\prod_{j=1}^{p}P(x_{j}|y=C_{j})$$
---

### 5. Métricas de Evaluación

Para medir el desempeño de estos modelos se utilizan las siguientes métricas:
- **Exactitud (Accuracy):** Fracción de predicciones correctas totales.
- **Recall (Sensibilidad):** Proporción de entradas de un estado identificadas correctamente.
- **Precisión:** Proporción de entradas clasificadas como positivas que realmente lo eran.
- **F1-Score:** Media armónica entre Recall y Precisión; útil para tener una referencia balanceada.
---

### 6. Caso de Estudio: Dataset Iris

El documento utiliza el clásico conjunto de datos **Iris** (Fisher, 1936) para ejemplificar la clasificación.
- **Contenido:** 150 muestras de 3 especies de flores (Setosa, Virginica, Versicolor).
- **Variables (Rasgos):** 4 variables continuas medidas en cm (Largo y ancho del sépalo; Largo y ancho del pétalo).
- **Objetivo:** Distinguir entre especies basándose en la combinación de estos rasgos.

https://www.datacamp.com/es/tutorial/naive-bayes-scikit-learn

https://www.ibm.com/think/topics/naive-bayes

https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/